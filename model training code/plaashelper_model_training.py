# -*- coding: utf-8 -*-
"""PlaasHelper Model Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zR6tZ-_NjcgjQqFHbbtGCddm1ifBsjX0

Mount Data Set From Google Drive where I have stored it.
"""

from google.colab import drive
import zipfile
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
tf.test.gpu_device_name()

drive.mount('/content/gdrive/')

dataset_zip_path = '/content/gdrive/My Drive/PlaasHelper/Crop Leaf Data Set.zip'
extracted_dataset_path = '/content/dataset/Crop Leaf Data Set/Crop Leaf Data Set/Crop Leaf Data Set'

"""Extract data set"""

with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_dataset_path)

root_path = extracted_dataset_path

target_size = (150, 150)  # You can adjust this size as needed
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    os.path.join(root_path, 'train'),
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(root_path, 'valid'),
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical'
)

# Define the model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))
model = Sequential([
    base_model,
    Flatten(),
    Dense(512, activation='relu'),
    Dense(len(train_generator.class_indices), activation='softmax')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=10,  # You can adjust the number of epochs
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size
)

# Save the model
model.save('/content/gdrive/My Drive/PlaasHelper/crop_disease_model.h5')

print("Training completed and model saved.")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

def create_simple_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(27, activation='softmax')  # Adjust according to your number of classes
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Save the model
model = create_simple_model()
model.save("test55_model.h5")

# Load the model
try:
    model = tf.keras.models.load_model("disease.h5")
    print("Model loaded successfully!")
except Exception as e:
    print(f"Error loading model: {e}")

import tensorflow as tf
print(tf.__version__)